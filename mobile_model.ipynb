{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4b3f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anacond3_9\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anacond3_9\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "116/116 [==============================] - 106s 848ms/step - loss: 0.4641 - accuracy: 0.8063 - val_loss: 0.2075 - val_accuracy: 0.9528\n",
      "Epoch 2/7\n",
      "116/116 [==============================] - 105s 905ms/step - loss: 0.1908 - accuracy: 0.9437 - val_loss: 0.1259 - val_accuracy: 0.9678\n",
      "Epoch 3/7\n",
      "116/116 [==============================] - 131s 1s/step - loss: 0.1411 - accuracy: 0.9499 - val_loss: 0.0987 - val_accuracy: 0.9689\n",
      "Epoch 4/7\n",
      "116/116 [==============================] - 160s 1s/step - loss: 0.1176 - accuracy: 0.9610 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
      "Epoch 5/7\n",
      "116/116 [==============================] - 189s 2s/step - loss: 0.0991 - accuracy: 0.9689 - val_loss: 0.0713 - val_accuracy: 0.9839\n",
      "Epoch 6/7\n",
      "116/116 [==============================] - 184s 2s/step - loss: 0.0856 - accuracy: 0.9724 - val_loss: 0.0641 - val_accuracy: 0.9839\n",
      "Epoch 7/7\n",
      "116/116 [==============================] - 173s 1s/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.0567 - val_accuracy: 0.9861\n",
      "30/30 [==============================] - 41s 890ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mask       0.98      0.98      0.98       376\n",
      "     no_mask       0.99      0.99      0.99       557\n",
      "\n",
      "    accuracy                           0.99       933\n",
      "   macro avg       0.99      0.99      0.99       933\n",
      "weighted avg       0.99      0.99      0.99       933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "folder = r\"C:\\Users\\Rajath\\Desktop\\Face-Mask-Detection-master\\dataset\\train\"\n",
    "category = [\"mask\", \"no_mask\"]\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for ca in category:\n",
    "    path = os.path.join(folder, ca)\n",
    "    for im in os.listdir(path):\n",
    "    \tim_path = os.path.join(path, im)\n",
    "    \timg = load_img(im_path, target_size=(224, 224))\n",
    "    \timg = img_to_array(img)\n",
    "    \timg = preprocess_input(img)\n",
    "\n",
    "    \tx.append(img)\n",
    "    \ty.append(ca)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "x = np.array(x, dtype=\"float32\")\n",
    "y = np.array(y)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(x, y,\n",
    "\ttest_size=0.20, stratify=y, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "augment = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "bm = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "\n",
    "hm = bm.output\n",
    "hm = AveragePooling2D(pool_size=(7, 7))(hm)\n",
    "hm = Flatten(name=\"flatten\")(hm)\n",
    "hm = Dense(128, activation=\"relu\")(hm)\n",
    "hm = Dropout(0.5)(hm)\n",
    "hm = Dense(2, activation=\"softmax\")(hm)\n",
    "\n",
    "\n",
    "mobile_model = Model(inputs=bm.input, outputs=hm)\n",
    "\n",
    "\n",
    "for layer in bm.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "optimiser = Adam(lr=0.0001, decay=0.0001 / 20)\n",
    "mobile_model.compile(loss=\"binary_crossentropy\", optimizer=optimiser,metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H = mobile_model.fit(augment.flow(x_train, y_train, batch_size=32),steps_per_epoch=len(x_train) // 32,validation_data=(x_test, y_test),validation_steps=len(x_test) // 32,epochs=7)\n",
    "\n",
    "pred = mobile_model.predict(x_test, batch_size=32)\n",
    "\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.argmax(axis=1), pred,target_names=lb.classes_))\n",
    "\n",
    "mobile_model.save(\"mobilenetv2.model\", save_format=\"h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb50610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 26s 870ms/step\n",
      "[[9.9999857e-01 1.4739564e-06]\n",
      " [6.8865402e-06 9.9999309e-01]\n",
      " [3.3666131e-01 6.6333872e-01]\n",
      " ...\n",
      " [1.0923641e-02 9.8907638e-01]\n",
      " [6.7912021e-07 9.9999928e-01]\n",
      " [9.9999726e-01 2.7443475e-06]]\n"
     ]
    }
   ],
   "source": [
    "pred = mobile_model.predict(x_test, batch_size=32)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a7fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
